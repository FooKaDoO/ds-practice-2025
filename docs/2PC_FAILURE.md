# Failure of a service

In the case, where the payments service breaks before committing, we needed to check, if the commit actually happened (did we get a response). Until the service is back up, we keep resending commit requests for the order. If the service saved its state when preparing, it can restore and commit when requested (otherwise it will let the executor know that there is nothing to commit).

The service can actually break at the Prepare stage as well. In that case, there are multiple options: it managed to prepare but not save state and not return, it managed to prepare and save state but not return, it didn't manage to do anything. The most complicated case is the first one, where the service would need to overwrite what it prepared or assume the save state by comparing the prepared result to the last saved state. All the other parts are mitigated with the following logic in the executor: since we are unsure, if preparing was succesful, we assume it was succesful and start trying to commit. We commit until the service is up and when it is up, it will let us know, if it managed to commit or there is nothing to commit. If there is nothing to commit, then just retry the entire 2PC cycle (prepare then commit).

# Failure of the coordinator

Although, failure of the coordinator causes usually the most issues (it needs to take into account all the services), from the perspective of solely 2PC, there are not many failure points. We have the following cases:
1. orchestrator didn't manage to even send the prepare;
2. orchestrator sent the prepare and failed before getting a response;
3. orchestrator sent the prepare and failed after the response;
4. orchestrator sent the commit and failed before getting a response;
5. orchestrator sent the commit and failed after getting the response.

The 1st and 5th cases are trivial. For the 1st, by keeping a similar state record, just send the prepare and commit again after back up again. The 5th is already solved since it is commited and orchestrator knows. The 3rd is also very similar to the first and can continue sending the commit after back up again based on the state record. The 2nd and 4th are more tricky since the service has already updated, but the orchestrator has no idea. For the 2nd, there can be a timeout implementation, where if a request has not been commited in a certain timeframe, it will be reverted. Another option for the 2nd is to use deterministic IDs. Then, the orchestrator can just retry to send a prepare request and the service can let the orchestrator know that it has already been prepared, but this might cause issues with ID collision (same id, different data, but it can be mitigated by also matching the data from the request to the prepared data). Finally, the most complicated, 4th option. The request has been prepared and potentially commited but the orchestrator has no idea. Using the recorded state, it will think that there has yet to be a commit, so it will retry. If the commit didn't go through, then it will just be retried now and the orchestrator will get to know the answer. The more problematic part is when the commit went through. Then the service will respond with "no such order found" and the orchestrator won't know if the commit failed or was succesful (thankfully, since we have the state record, we know that the preparation was succesful). In the case it failed, we want to retry the entire request (prepare, commit), but in the case it was succesful, we cannot, since it will cause a double spending problem (same transaction commited twice, but orchestrator thinks once). Naively, the service could keep a record of commits, but if there is a large amount of commits, then searching if the current order is in there, will be slow (there could be a lifetime or maximum commit history length to mitigate this, and remove the commits orchestrator acknowledged that happened).